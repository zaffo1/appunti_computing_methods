\chapter{Machine Learning}

\section{\textit{Gio 3 novembre - Lezione 12}}
\section{Introduction to Machine Learning}

\subsection{Topics}

\begin{enumerate}
	\item Introduction to machine learning
	\begin{enumerate}
		\item Basic concepts: loss, overfit, underfit
		\item Examples of linear regression, boosted decision trees
		\item Exercise with colab, numpy, scikit
	\end{enumerate}
	\item Deep Neural Networks
	\begin{enumerate}
		\item Basic FeedForward networks and backpropagation
		\item Importance of depth, gradient descent, optimizers
		\item Introduction to tools and first exercises
	\end{enumerate}
	\item Convolutional and Recurrent networks
	\begin{enumerate}
		\item Reduction of complexity with invariance: RNN and CNN
		\item CNN exercise
	\end{enumerate}
	\item Autoencoders and Generative Adversarial Networks
	\begin{enumerate}
		\item GAN exercises
	\end{enumerate}
	\item Graph Neural Networks
	\begin{enumerate}
		\item PointCloud exercise
	\end{enumerate}
\end{enumerate}

\subsection{Machine Learning Basics}
\textbf{Wikipedia:} Machine learning (ML) is a field of inquiry devoted to understanding and building methods that \textit{'learn'}, that is, methods that leverage data to improve performance on some set of tasks. It is seen as a part of \textit{artificial intelligence}. Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions \textbf{without being explicitly programmed to do so}. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\\

Noi siamo abituati a dare al computer degli ordini imperativi.\\

In experimental and applied physics examples are everywhere...
\begin{itemize}
	\item Particle identification and kinematic measurement
	\item Signal to background discrimination (BDT and DNN are very popular in HEP experiments)
	\item Computer assisted processing of medical exams (ECG, CT, etc...)
	\item Processing of astrophysics data
\end{itemize}

\subsection{Types of typical ML problems}


\begin{itemize}
	\item \textbf{Classification:} which category a given input belongs to. 
	\item \textbf{Regression:} value of a real variable given the input.
	\item \textbf{Clustering:} group similar samples
	\item \textbf{Anomaly detection:} identify inputs that are “different” from the others
	\item \textbf{Generation/synthesis of samples:} produce new samples, similar to the original data, starting from noise/random numbers
	\item \textbf{Denoising:} remove noise from an input dataset
	\item \textbf{Transcriptions:} describe in some language the input data
	\item \textbf{Translations:} translate between languages
	\item \textbf{Encoding and decoding:} transform input data to a different representation
	\item ...many more...
\end{itemize}


\begin{tcolorbox}[width=\textwidth,colback={white},title={Classification vs Regression },colbacktitle=cyan,coltitle=black]
	\begin{itemize}
			\item \textbf{Regression} algorithms predict a continuous value based on the input variables. The main goal of regression problems is to estimate a mapping function based on the input and output variables.
			\item \textbf{Classification} is a predictive model that approximates a mapping function from input variables to identify discrete output variables, which can be labels or categories. The mapping function of classification algorithms is responsible for predicting the label or category of the given input variables. A classification algorithm can have both discrete and real-valued variables, but it requires that the examples be classified into one of two or more classes.

The most significant difference between regression vs classification is that while regression helps predict a continuous quantity, classification predicts discrete class labels. \\

Let’s consider a dataset that contains student information of a particular university. A regression algorithm can be used in this case to predict the height of any student based on their weight, gender, diet, or subject major. We use regression in this case because height is a continuous quantity. There is an infinite number of possible values for a person’s height.\\

On the contrary, classification can be used to analyse whether an email is a spam or not spam. The algorithm checks the keywords in an email and the sender’s address is to find out the probability of the email being spam. Similarly, while a regression model can be used to predict temperature for the next day, we can use a classification algorithm to determine whether it will be cold or hot according to the given temperature values. 
	\end{itemize} 
\end{tcolorbox}

\subsection{Function approximation}

The goal of a ML algorithm is to approximate an unknown function (often related to some Probability Density Function of the data) given some example data.\\
The function is often $ f(\textbf{x}): R^n \rightarrow R^m$ (in many simple problems $m=1$)
\begin{itemize}
	\item In \textbf{classification} we try to approximate the probability for each example, given the inputs represented as a vector \textbf{x}, to belong to a given category (y) (e.g. the probability to be a LHC Higgs signal event vs a Standard Model background one)
	\item In \textbf{regression} we approximate the function that given the inputs (x) returns the value of the variable to predict (y) (e.g. given the data read from some particle detectors, estimate the particle energy).
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\textwidth]{figure_ml/function_approx.png}
\end{figure}
\FloatBarrier

\subsection{Model and Hyper-parameters}
A model for the functions that can be used to approximate the “f(x)” must be defined. The model can be something simple (e.g. sum of polynomials up to degree N) or more complex (e.g. all the functions that could be coded in M lines of C++).\\
Different ML techniques are based on different “models”:
\begin{itemize}
	\item Each technique (“class of model”) further allow to specify the exact model
	\item The parameters describing the exact model are called “hyper-parameters” (e.g. the degree N of the polynomial, or the maximum number of C++ line M can be considered hyper
	parameters)
\end{itemize}

We will see example of techniques with different models and complexity: (Linear regression, Decision trees, Principal Component Analysis, Nearest Neighbor, Artificial Neural Networks).

\subsection{Parameters}

A specific model typically have parameters (e.g. the coefficients of the polynomials or the characters of the 10 lines of C++).
\textbf{Parameters are what we learn from data in the “training phase”}.
Different models or similar model with different hyper-parameters settings have different n.d.o.f. in the parameters phase space.
\begin{equation*}
	y(x) = ax + bx^2 + cx^3 + d \qquad \qquad	\text{(a, b, c, d are the parameters)}
\end{equation*}

I parametri sono la cosa che voglio imparare nella fase di training. Mentre gli iperparametri li fisso prima di allenare il modello facendogli vedere i dati, i parametri sono invece proprio quelli che imparo.

\section{Objective function}
Dobbiamo stabilire una metrica per dire quanto è buona la nostra approssimazione, dati gli esempi su cui ci stamo allenando.\\

A goal for what is “a good approximation” have to be defined. This is called objective function (or loss function or error function …)- It is a function that returns higher (or lower) value depending how good or bad the approximation is. \textbf{Loss functions have to be minimized}.\\
Examples of loss functions are:
\begin{itemize}
	\item Classification problems: binary cross entropy
	\item Regression problems: Mean Square Error (i.e. the chi2 with sigma=1, I hope you are not surprised by this choice!)
\end{itemize}

The process is not very different from a typical phys-lab1 chi2 fit… but the number
of parameters can be several orders of magnitude larger ($10^3$ to $10^6$).\\


\begin{tcolorbox}[width=\textwidth,colback={white},title={\textbf{19:} What is a loss function? Which properties should it have in order to be used in a gradient descent technique? Which loss functions are more appropriate for classification vs regression problems?},colbacktitle=red,coltitle=black]
	
Anche nota come objective function o error function. E’ una funzione che mappa un evento, o valori di una o più variabili, su un numero reale, che intuitivamente rappresenta un "costo" associato all'evento. Rappresenta una metrica che quantifica la bontà dell’approssimazione realizzata dal nostro modello.\\

Le tecniche di gradient descent servono a minimizzare la cost function. In particolare, dato che si basano sul calcolo di derivate prime, è necessario che la loss function usata sia differenziabile.\\

Classification problems $\rightarrow$ binary cross entropy\\
Regression problems  $\rightarrow$ Mean Squared Error Loss (MSE)\\

\end{tcolorbox}

\subsection{Function approximation}

\subsubsection{Objective function: binary cross entropy}
In classification problems the function to approximate is typically $R^n \rightarrow [0,1]$, Where, for example, 0 means background and 1 means signal.\\
The binary cross entropy is defined as follows ($\hat{y}_i$ is the output of the classifier)

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{figure_ml/D_bce.png}
\end{figure}
\FloatBarrier
The above function has large value when an example with y=1 is classified as 
a  $\hat{y}_i \sim 0$ and no loss when $\hat{y}_i \sim 1$. Viceversa if y=0 …\\
Minimizing the binary cross-entropy we maximize the likelihood in a process with 0/1 outcome (where the output of the function is interpreted as a probability).

\begin{figure}[h]
	\centering
	\includegraphics[width=0.65\textwidth]{figure_ml/L_bce.png}
\end{figure}
\FloatBarrier

\subsection{Learning / Training}
For a given model, and given set of hyper-parameters, how do we infer the parameters that minimize the objective function? The idea of ML is to get the parameters from “data” in a so called “training” step. Each ML technique has a different approach to training.\\
Different types of training:
\begin{itemize}
	\item \textbf{Supervised}: i.e. for each example we know the correct answer
	\item \textbf{Unsupervised}: we do not know “what is what”, we ask the ML algorithm to learn the probability density function of the examples in the features (i.e. the inputs!) space
	\item \textbf{Reinforcement learning}: have agents playing a punishment/reward game
\end{itemize}

\subsubsection{Supervised learning}

We want to teach something we (the supervisors) already know (at least on the training samples). For each example we need to have the “right answer” / “truth”, for example:

\begin{itemize}
	\item Labels telling if a given example signal or background, typically $y \in{0,1}$ (e.g. 0=background, 1=signal)
	\item Labels classifying the content of an image (multiple labels are possible)
	\item One-hot encoding used when multiple categories are possible:
	\begin{itemize}
		\item y=[0 1 0 0] means an element of the “2nd class”, y=[0 0 0 1] means an element of the “4th class”
		\item Much better than $y\in {0,1,2,3}$ if class “2” has no reason to be closer to “3” than to “0”
		\item Allows interpretation of the output (e.g. [0.1 0.3 0.06 0.001 ] as the probability to belong to each of the classes
		\item Allow for multi labeling (i.e. one sample can be belong to more than one category)
	\end{itemize}
	\item In regression problems the “truth” is the “correct values” of some quantity
	\begin{itemize}
		\item e.g. generated energy of a particle in a detector simulation
	\end{itemize}
\end{itemize}

Sample can be labelled in various ways:
\begin{itemize}
	\item Humans labelling existing data
	\item Data being “generated” from known functions (e.g. simulations)
\end{itemize}

Learn the probability of the label y, given the input \textbf{x}, i.e. P(y|\textbf{x})

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\textwidth]{figure_ml/supervised_learning.png}
\end{figure}
\FloatBarrier

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.4\textwidth]{figure_ml/multi_class.png}
\end{figure}
\FloatBarrier

\subsubsection{Unsupervised learning}

\begin{wrapfigure}{r}{0.5\textwidth}
	\includegraphics[width=0.5\textwidth]{figure_ml/unsupervised.png}
\end{wrapfigure} 

Often we do not have labels (or we have labels only for few data points). Unsupervised learning techniques allow to train networks that can perform
similar tasks as the supervised ones, e.g.

\begin{itemize}
	\item Classification of “common” patterns (clustering)
	\item Dimensionality reduction, compression
	\item Prediction of missing inputs
	\item Anomaly detection
\end{itemize}



In practice learn the Probability Density Function of the data, independently of any “label” variable, i.e. P(\textbf{x})

\begin{tcolorbox}[width=\textwidth,colback={white},title={\textbf{23.} Can you make some examples of unsupervised algorithms ?
	},colbacktitle=red,coltitle=black]
	
	Unsupervised learning is a machine learning technique in which developers don’t need to supervise the model. Instead, this type of learning allows the model to work independently without any supervision to discover hidden patterns and information that was previously undetected. It mainly deals with the unlabeled data, while supervised learning, as we remember, deals with labeled data.
	Unsupervised learning tasks and the algorithms used to solve them:
	
	\begin{itemize}
		\item \textbf{Dimensionality Reduction}— the task of reducing the number of input features in a dataset
		\begin{itemize}
			\item Principal Component Analysis;
			\item Autoencoders
		\end{itemize}
		\item \textbf{Anomaly Detection}— the task of detecting instances that are very different from the norm, and
		
		\item \textbf{Clustering} — the task of grouping similar instances into clusters.
		
		\item \textbf{Prediction of missing inputs
		}
	\end{itemize}
	 
\end{tcolorbox}

\subsubsection{Supervised vs unsupervised}


Supervised and unsupervised are not as different as one would imagine, in fact.\\
Unsupervised P(\textbf{x}) can be seen as n supervised problems, one for each feature of the input vector

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.4\textwidth]{figure_ml/s_vs_u.png}
\end{figure}
\FloatBarrier

Supervised P(y | \textbf{x}) can also be computed, if we treat y as an “\textbf{x}” in unsupervised learning deriving hence $p(\textbf{x},y)$
, as


\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\textwidth]{figure_ml/s_vs_u2.png}
\end{figure}
\FloatBarrier

\begin{tcolorbox}[width=\textwidth,colback={white},title={\textbf{24.} How can a supervised algorithm be seen as an unsupervised one and vice versa?
		
	},colbacktitle=red,coltitle=black]
	
 Vedi sopra...
	
\end{tcolorbox}


\subsubsection{Reinforcement learning (not covered in this lectures)}
\begin{wrapfigure}{r}{0.5\textwidth}
	\includegraphics[width=0.5\textwidth]{figure_ml/reinforcement_learning.png}
\end{wrapfigure} 

Applies to “agents” acting in an “environment” that updates their state.\\
It is similar to supervised learning as a “reward” has to be calculated. The supervisor anyhow doesn’t necessarily know what is the best action to perform in a given state to interact with the environment, it just computes the final reward.\\
Learn to make best decision in a given situation
\begin{itemize}
	\item The right move in chess or go match
	\item Drive a car in the traffic
\end{itemize}


\subsection{Capacity and representational power}

\begin{wrapfigure}{r}{0.25\textwidth}
	\includegraphics[width=0.25\textwidth]{figure_ml/capacity.png}
\end{wrapfigure} 

Different models (i.e. ML techniques/hyper-parametersvalues) allow to represent different type of functions.
Models with more free parameters typically can approximate a larger number
of functions (or can better approximate a given function) => higher capacity.
Remember: we do not know the actual function to approximate, we just want
to learn from examples.
With limited samples we have a tradeoff to
handle: accuracy in representation vs generalization of the results.\\


\noindent
\textbf{Underfitting:} the sample is badly represented.\\
\textbf{Overfitting} / Appropriate capacity are less obvious to define. (Lack of “generalization” $\rightarrow$ overfitting).

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.5\textwidth]{figure_ml/u_a_o.png}
\end{figure}
\FloatBarrier

Typical method is to check on independent sample for the same process (Or just split your sample in two and use only half for training).

\begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth]{figure_ml/u_a_o2.png}
\end{figure}
\FloatBarrier

\subsection{Generalization}

We can compare the accuracy between the “training” sample and the “generalization/validation” sample.\\

\begin{figure}[ht]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/generalization.png}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/generalization2.png}
	\end{subfigure}
	
\end{figure}



Bias/variance trade-off
\begin{itemize}
	\item y: function (with random noise)
	\item h(x): approximated function
\end{itemize}


\begin{figure}[ht]
	\centering
	\includegraphics[width=0.45\textwidth]{figure_ml/generalization3.png}
\end{figure}
\FloatBarrier


\begin{tcolorbox}[width=\textwidth,colback={white},title={\textbf{20.} How can you see that ML training is overfitting?  What is the bias vs variance tradeoff?
		
		
	},colbacktitle=red,coltitle=black]
L’overfitting corrisponde ad una mancanza di generalizzazione. Un modello affetto da overfitting predice bene i training data, ma predice male i dati di almeno uno tra test e validation set.\\

Overfitting è sinonimo di high variance: variance is an error of the model due
to its sensitivity to small fluctuations in the training set. It means that if your training data
was sampled differently, the learning would result in a significantly different model. Which
is why the model that overfits performs poorly on the test data: test and training data are
sampled from the dataset independently of one another.\\

Underfitting invece è sinonimo di high bias: a model has a low bias if it predicts well
the labels of the training data. If the model makes many mistakes on the training data, we
say that the model has a high bias or that the model underfits. So, underfitting is the
inability of the model to predict well the labels of the data it was trained on.\\

Dunque il variance-bias tradeoff si riferisce a trovare un compromesso tra underfitting e overfitting. Tipicamente questo viene fatto grazie alla regolarizzazione, che comporta un leggero aumento del bias, ma allo stesso tempo riduce significativamente la varianza.

	
\end{tcolorbox}


\subsection{Regularization}

\begin{wrapfigure}{r}{0.45\textwidth}
	\includegraphics[width=0.45\textwidth]{figure_ml/regularization.png}
\end{wrapfigure} 

Vogliamo evitare che "impari a memoria" il set.\\
In order to control the “generalization gap”. the objective function can be modified adding a regularization term (Introduce a “cost” in increasing the capacity of the model or in accessing some parts of the model-parameters space).\\

the examples in training dataset can be increased with augmentation techniques:

\begin{itemize}
	\item Adding stochastic noise to existing examples
	\item Transforming the existing examples with transformation that are known to be invariant 	for the solution we look for
\end{itemize}


\url{https://xgboost.readthedocs.io/en/latest/tutorials/model.html}



\subsection{Hyperparameters (model) optimization}

It is normal to have to test a few, if not several, configurations in the model hyper-parameter space:
\begin{itemize}
	\item Scans of hyper-parameters are often performed
	\item Different techniques used
\end{itemize}


Effectively a “second” minimization is done

\begin{itemize}
	\item First minimization is on the parameter => minimize on the “training dataset”
	\item Second minimization is on the hyper-parameters => minimize on the “validation dataset”
\end{itemize}

A third dataset (“test dataset”) is then also needed

\begin{itemize}
	\item To assess the performance of the algorithm in an unbiased way
	\item To make an unbiased prediction of the algorithm output
\end{itemize}


Original dataset is typically split in uneven parts to be used as \textit{training}, \textit{validation} and \textit{test}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth]{figure_ml/hyperparams_optimization.png}
\end{figure}
\FloatBarrier

\begin{tcolorbox}[width=\textwidth,colback={white},title={\textbf{21.} What is hyper-parameter optimization and why would it require additional splitting of the available dataset?
		
		
	},colbacktitle=red,coltitle=black]
La minimizzazione sul training set serve per trovare i parametri ottimali di un dato modello.
A questo punto si usa il validation set per valutare le performance del modello. Si possono cambiare gli iperparametri cercando di fare una minimizzazione sul validation set e trovare gli iperparametri ottimali. A questo punto entra in gioco il test set, che serve per fare un performance assessment del nostro algoritmo che sia unbiased.
	
	
\end{tcolorbox}

\subsection{K-folding cross validation}

If the sample is statistically limited, splitting in 3 chunks means loosing
examples.\\
With K-folding, “K” independent trainings are performed, each using a
different chunk of data for “training” and for “testing” (and another one for
validation if a hyper parameter scan is performed)

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth]{figure_ml/k-folding.png}
	\caption{Nella figura i dati sono divisi solo in 2 (test e training), ma si possono dividere in 3 come abbiamo visto prima}
\end{figure}
\FloatBarrier

\begin{tcolorbox}[width=\textwidth,colback={white},title={\textbf{25.} What are k-folding and cross-validation?
		
		
		
	},colbacktitle=red,coltitle=black]

	Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\\
	The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation.\\
	The general procedure is as follows:
	\begin{enumerate}
		 
	
	\item Shuffle the dataset randomly.
	\item Split the dataset into k groups
	\item For each unique group:
	\begin{enumerate}
		 
	\item Take the group as a hold out or test data set
	\item Take the remaining groups as a training data set
	\item Fit a model on the training set and evaluate it on the test set
	\item Retain the evaluation score and discard the model
	\end{enumerate}
	\item Summarize the skill of the model using the sample of model evaluation scores
	\end{enumerate}
	
	Importantly, each observation in the data sample is assigned to an individual group and stays in that group for the duration of the procedure. This means that each sample is given the opportunity to be used in the hold out set 1 time and used to train the model k-1 times
	
	
	
\end{tcolorbox}

\subsection{Inference}

A ML model that has been trained can than be used to act on some new data (or on the test dataset if a prediction has to be made).
The evaluation of the algorithm output on the “unseen” data is called inference. From a computing time point of view inference is usually much faster than training.

\subsection{Accuracy, Precision, Sensitivity, Specificity}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\textwidth]{figure_ml/apss.png}
\end{figure}
\FloatBarrier


\section{Examples of ML techniques}

\subsection{Linear regression (Supervised)}

Solve a regression problem, i.e. predict the value of y when \textbf{x} is given. Approximate an unknown “y=f(\textbf{x})” given some examples of (y,\textbf{x})\\

\textbf{Model:} $y=w_ix_i$ , i.e. the function is a linear combination of the input parameters\\

\textbf{Parameters:} $ w_i$\\

Let’s suppose we have m examples in the form of pairs $(\textbf{x},y)_j$\\

The \textbf{objective function} can be the mean squared error, MSE=$|y_j - w_i x_{ij} |^2/m$\\

\textbf{Training}: find the parameters $w_i$ that minimize the MSE on the given dataset. Linear regression have an analytical solution (i.e. a minimum for the MSE) that can be computed by requiring the gradient of the MSE to be zero (if you want to see the math \url{https://en.wikipedia.org/wiki/Linear_regression#Least-squares_estimation_and_related_techni
	ques}.

We could increase the \textbf{capacity} of the model using polynomials instead of linear functions.The number of parameters would increase as we now would have the second order
coefficients too
\subsection{Principal Component Analysis (aka PCA) (Unsupervised)}

\begin{wrapfigure}{r}{0.45\textwidth}
	\includegraphics[width=0.45\textwidth]{figure_ml/pca.png}
\end{wrapfigure} 

Orthogonal transformation of the input phase space such that
\begin{itemize}
	\item The first transformed coordinate has maximum variance 
	\item The 2nd transformed coordinated has 2nd max variance
	\item etc.
\end{itemize}

Can be computed as the eigenvalue decomposition of the
covariance matrix

\begin{figure}[ht]
	\includegraphics[width=0.35\textwidth]{figure_ml/pca_covariance.png}
\end{figure}
\FloatBarrier

Useful to transform the data in a normalized form (scaling by the variance of each component).\\
Reduce dimensionality (by taking only first N components) capturing only the largest deviations from the mean value.\\

More complex dimensionality reduction Manifold Learning:\url{https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.10-Manifold-Learning.ipynb}

\subsubsection{Nearest neighbors}

A very powerful way to do classification or regression is to look at points in the training datasets that are close to sample
to evaluate.
Multiple neighbors can be used for
a more stable evaluation.
On large dataset it could be a problem to keep all training points for the evaluation phase.


\begin{figure}[ht]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/nn.png}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/nn2.png}
	\end{subfigure}
	\caption{
		Figures from \url{https://scikit-learn.org/stable/modules/neighbors.html}.
	}
\end{figure}


\subsection{Decision trees}

The functions used in the “model” are decision trees, each node has a pass/fail condition on some input variable.\\
Classification and regression trees (CART)
\begin{itemize}
	\item Examples are categorized based on individual “cuts” on a single input feature
	\item A score is given in each leaf
\end{itemize}
Trees can have different depths (depth is an hyper-parameter)

\begin{figure}[ht]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/decision_trees.png}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/decision_trees2.png}
	\end{subfigure}
\end{figure}



\url{https://xgboost.readthedocs.io/en/latest/tutorials/model.html}


\subsection{Ensembles of trees}

A single tree is typically not a very performant.\\
Combine multiple trees (\#trees is an hyperpar)
\begin{itemize}
	\item Random forest (bagging)
	\item Gradient boosting
	\item Adaptive boosting
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.5\textwidth]{figure_ml/trees.png}
\end{figure}
\FloatBarrier

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.5\textwidth]{figure_ml/bagging.png}
	\caption{Bagging}
\end{figure}
\FloatBarrier



\begin{figure}[ht]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/g_b.png}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/g_b2.png}
	\end{subfigure}
	\caption{Gradient Boosting}
\end{figure}


\begin{tcolorbox}[width=\textwidth,colback={white},title={\textbf{26.} What is the difference between bagging and boosting for decision trees?
		
		
		
		
	},colbacktitle=red,coltitle=black]
	
Sono entrambi metodi utilizzati per combinare più decision tree.
\textit{Ensemble methods}, which combine several decision trees to produce better predictive performance than utilizing a single decision tree. The main principle behind the ensemble model is that a group of weak learners come together to form a strong learner.\\

\textbf{Bagging} (Bootstrap Aggregation) is used when our goal is to reduce the variance of a decision tree. Here idea is to create several subsets of data from training sample chosen randomly with replacement. Now, each collection of subset data is used to train their decision trees. As a result, we end up with an ensemble of different models. Average of all the predictions from different trees are used which is more robust than a single decision tree.\\

\textbf{Boosting} is another ensemble technique to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analyzing data for errors. In other words, we fit consecutive trees (random sample) and at every step, the goal is to solve for net error from the prior tree.


	
	
\end{tcolorbox}

\subsection{Limitations of decision trees}
Cuts are axis aligned!\\
Classification of \textbf{x1 > x2} is a hard problem for a decision tree


\begin{figure}[ht]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figure_ml/limitations_trees.png}
	\end{subfigure}%
	\begin{subfigure}{.6\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figure_ml/limitations_trees2.png}
	\end{subfigure}
\end{figure}
\FloatBarrier


\subsection{Decision Trees tools}
Very powerful tools (e.g. the “workhorse” for classification/regression at the LHC).\\

Various tools exists for using decision trees in python\\
\begin{itemize}
	\item In python environment: XGBoost, sklearn.tree
	\item In ROOT libraries the “TMVA” package supports boosted decision trees (BDT)
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\textwidth]{figure_ml/decision_trees_tools}
\end{figure}
\FloatBarrier

\subsection{Many more ML techniques!}

Scikit-learn library offers many ML techniques implementation in python.\\
\url{https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\textwidth]{figure_ml/scikit.png}
\end{figure}
\FloatBarrier

\subsection{What do we need to create our first ML program}

-Load some data
\begin{itemize}
	\item We use numpy arrays as data structures, today we load data from some existing repositories
	\item We need an “X” and a “y” array for input data and for labels (for a supervised algorithm)
	\item Different examples on the same dataset are placed in ROWS
	\begin{itemize}
		\item Rows are corresponding to the first index in numpy multi index array (aka tensor)
		\item Columns correspond to different “input features”
	\end{itemize}
\end{itemize}

-Use some existing library implementing a ML algorith (Python library exists for almost any ML algorithm).\\

-Feed the data to the library (We need to understand for each library how you run the “training” step)\\

Check the result: We need to understand how to do the inference of a trained model, for example on a new sample or on a new dataset.

\subsection{Hands-on}


First exercise is taken from \href{http://shop.oreilly.com/product/0636920034919.do}{Python Data Science Handbook} by Jake
VanderPlas with some minor edits (the content is available on \href{https://github.com/jakevdp/PythonDataScienceHandbook}{GitHub} 
Click here and “make a copy” to be able to edit: \url{https://colab.research.google.com/drive/1Sqn5fuiB5-2EP6UKUmwqjQd_b3uUNu2r?usp=sharing}\\
NB: the example uses scikit learn library, that we will NOT use in the next lectures

\includepdf[pages=-]{Copy_of_Scikit-Learn.pdf}
%\subsection{Python numpy reshape and stack cheatsheet}
\includepdf[pages=-]{reshape.pdf}

\section{\textit{Lun 7 novembre - lezione 13}}

\section{Introduction to Artificial Neural Networks}

\begin{tcolorbox}[width=\textwidth,colback={white},title={Recap lezione 1 },colbacktitle=cyan,coltitle=black]
	\begin{itemize}
		\item ML techniques have common elements:
		\begin{itemize}
			\item The function “f” to approximate
			\item The model used to approximate “f” (e.g. polynomials functions or a decision tree or a NN)
			\item The parameters of the model (e.g. the coefficients of the poly) 
			\item The hyper-parameters of the models (e.g. the grade of the polynomial, N=1 for linear)
			\item The objective function (i.e. the loss such as MSE or binary cross entropy)
			\item The variance-bias tradeoff (aka training vs generalization)
			\item The regularization techniques
		\end{itemize}
		\item Example of ML algorithms
		\begin{itemize}
			\item Linear regression
			\item PCA
			\item Nearest Neighbours
			\item Decision trees
			\begin{itemize}
				\item Bagging vs boosting
			\end{itemize}
		\end{itemize}
	\end{itemize} 
\end{tcolorbox}

\section{Artificial Neural Networks}
\subsection{(Artificial) neural networks: the “Model”}


\begin{itemize}
	\item Computation achieved with a network of elementary computing units (neurons) 
	\item Each basic units, a neuron, has:
	\begin{itemize}
		\item \textbf{Weighted} input connections to other neurons
		\item A \textbf{non linear} activation function
		\item An output value to pass to other neurons
	\end{itemize}
	\item Biologically inspired to brain structure as a network of neuron
	\begin{itemize}
		\item But artificial NN goal is not that of “simulating” a brain!
	\end{itemize}
	\item Actual modern NN go much beyond the brain-inspired models
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\textwidth]{figure_ml/model.png}
\end{figure}
\FloatBarrier

\subsection{Brief history, highs and lows}

\begin{wrapfigure}{r}{0.6\textwidth}
	\includegraphics[width=0.6\textwidth]{figure_ml/history.png}
\end{wrapfigure} 

\quad
\begin{itemize}
	\item First work originates back in ~1940-1960 “cybernetics” 
	\begin{itemize}
		\item Linear models
	\end{itemize}
	\item Then called “connectionism” in ’80-’90
	\begin{itemize}
		\item development of neural networks, backpropagation, non-linear activations (mostly sigmoid)
	\end{itemize}
	\item High expectations, low achievements in the ‘90
	\begin{itemize}
		\item A decade of stagnation
	\end{itemize}
	\item New name, “Deep Learning”, from 2006
	\begin{itemize}
		\item Deep architectures (see next slides)
		\item Very active field in the past decade
		\item Availability of GP-GPU game changing on typical “size”
		\item Processing raw, low level, features
		\begin{itemize}
			\item It doesn’t mean you \textbf{must} use “raw features” but that rather that you \textbf{can} use raw features!
		\end{itemize}
	\end{itemize}
\end{itemize}

Dal 2006 in poi è diventato disponibile un sistema di calcolo pensato per fare videogiochi (GPU), che però si prestano bene anche al calcolo necessario per questo tipo di computing.


\subsection{Complexity growth}
Dataset become larger and larger (“big data”). Not just in “industry”, experimental scientific research is now producing multi PetaByte datasets. Digital era => everything can be “data”.\\

Increasing hardware performance => increasing complexity of the network (number of neurons and connections).\\
\begin{itemize}
	\item 2020 largest ANN: OpenAI GPT3, 175 billion parameters ( $10^{11}$)
	\item 2021 “Switch transformer” and “Wu Dao 2.0” => trillion parameters models ( $10^{12}$ )
	\item (for comparison) Human brain $10^{13} - 10^{15} $synapses ( ~ parameters )
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\textwidth]{figure_ml/complexity_growth.png}
\end{figure}
\FloatBarrier

\subsection{Performance on classic problems}
Image classification and speech recognition are the typical problems where ML (and Neural Networks) failed in the 90’. Now it beats humans...
\begin{figure}[ht]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/speech.png}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/img_class.png}
	\end{subfigure}
\end{figure}


\subsection{My favorite performance examples}

\begin{itemize}
	\item 
\end{itemize}

\url{https://www.technologyreview.com/2020/11/03/1011616/ai-godfather-geoffrey-hinton-deep-learning-will-do-everything/}

\subsection{OpenAI GPT3}

Generative Pre-trained Transformer A 12M\$ autocomplete (that is not really understanding what is talking about, but can still write better than most of us). \url{https://openai.com/blog/openai-api/}\\
\url{https://doi.org/10.1007/s11023-020-09548-1}.
\section{Neural Nets Basic elements}
\subsection{A neural network node: the artificial neuron}
The elementary processing unit, a neuron, can be seen as a node in a directed graph. Inputs are \textbf{summed}, with \textbf{weights}, and an \textbf{activation function} is evaluated on such sum.\\
Nodes are typically also connected (with weight b) to an input “bias node” that has a fixed output value of 1. Different activation functions can be used, common ones are: sigmoid, atan, relu (rectified linear unit).

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\linewidth]{figure_ml/neuron.png}
\end{figure}
\FloatBarrier


\subsection{The MLP model}

\begin{wrapfigure}{r}{0.6\textwidth}
	\includegraphics[width=0.6\textwidth]{figure_ml/mlp.png}
\end{wrapfigure} 
\quad
\begin{itemize}
	\item The most common NN in the ‘90 was the Multi Layer	Perceptron (MLP)
	\item Graph structure organized in “layers”
	\begin{itemize}
		\item Input layer (nodes filled with input value)
		\item Hidden layer
		\item Output layer (node(s) where output is read out)
	\end{itemize}
	\item Nodes are connected only from one layer to the next and all possible connections are present (known as \textbf{“dense” or “fully connected”} layer)
	\begin{itemize}
		\item No intra-layer connections
		\item No direct connections from input to output
	\end{itemize}
	\item Size of input and output layers are fixed by the problem
	\item \textbf{Hyperparameters} are
	\begin{itemize}
		\item The size of the hidden layers
		\item The type of activation function
	\end{itemize}
	\item The \textbf{parameters} to learn are the weights of the connections
\end{itemize}

\subsection{Universal approximation theorem}
\textit{“One hidden layer is enough to represent (not learn) an approximation of any function to an arbitrary degree of accuracy”} (I. Goodfellow et al. 2016).\\

\begin{itemize}
	\item You can approximate any function with arbitrary precision having \textbf{enough hidden nodes} and the \textbf{right weights}
	\item How do you get the right weights? You need a “training” for your network
	\begin{itemize}
		\item The theorem does not say that one hidden layer (+ some training algorithm) is enough to find the optimal weights, just that they exists!
	\end{itemize}
	\item Achieving some (even modest with some metric) level of accuracy may need an unmanageable hidden layer size
	\begin{itemize}
		\item And may need an unreasonable number of “examples” to learn from
	\end{itemize}
\end{itemize}

\subsection{Example (1-D input)}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\linewidth]{figure_ml/example1d.png}
\end{figure}
\FloatBarrier

The Universal Approximation Theorem says that increasing \#nodes I can
increase the accuracy as much as I want. More hidden nodes, higher “capacity” => more accuracy

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\linewidth]{figure_ml/example1d2.png}
	\caption{\url{https://towardsdatascience.com/can-neural-networks-really-learn-any-function-65e106617fc6}}
\end{figure}
\FloatBarrier

\subsection{Training of an MLP}
How do I get the weights?\\
Remember: we do not know the function we want to approximate, we only have some “samples”.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\linewidth]{figure_ml/training_mlp.png}
\end{figure}
\FloatBarrier

\subsection{Training a NN}


\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=0.4\textwidth]{figure_ml/training_nn.png}
\end{wrapfigure} 

The goal of training is to minimize the objective
function (possibly both on the training and validation
sample). I.e. we want to minimize the loss as a function of the model parameters (i.e. the weights).\\
For a MLP the basic idea is the following


\begin{enumerate}
	\item Start with random weights
	\item Compute the prediction y\_pred for a given input x and compare target y\_true computing the loss (repeat for a few example, aka “one batch”)
	\item Estimate an update for the weights that reduces the loss
	\item Iterate from point (b), repeating for all samples
	\item When the sample has been used completely (end of an epoch), iterate from (b) again on all samples
	\item Repeat for multiple epochs
\end{enumerate}

The important point is how to implement point (c) => (stochastic) gradient descent.

\subsection{How to find a minimum?}


\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=0.4\textwidth]{figure_ml/find_minimum.png}
\end{wrapfigure} 

\textbf{Gradient Descent}\\
We know the loss function value in a point in the weights phase space (e.g. the initial set of random weights, or the iteration
N-1), computed numerically as the mean or the sum of the losses for each of our training examples.\\
We can compute the gradient of the loss function in that point, we expect the minimum on “the way down” hence we adjust our set of weights doing a “step” in the direction pointed by the gradient with a step size that is proportional to the length
of the gradient.\\

\textbf{Stochastic Gradient Descent (SGD):}
Compute the gradient on “batches” of events rather than full sample. The “noise” may help avoiding local minima.

\subsection{Not as simple as you would imagine}

A parameter named \textbf{learning rate} controls how big the step in the direction of the gradient is.
\begin{itemize}
	\item A too large step may let you bounce back and forth on the walls of your “valley”
	\item A too small step would make your descent lasting forever
\end{itemize}
Several variants of SGD
\begin{itemize}
	\item Include “momentum” from previous gradient	calculations (may help overcome local obstacles) 
	\item Reduce step size over time
	\item Adadelta, Adagrad, \textbf{Adam}, and many more
\end{itemize}


\begin{figure}[ht]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/sgd.png}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/sgd2.png}
	\end{subfigure}
\end{figure}



\subsection{Learning rate, epochs and batches}


\begin{wrapfigure}{r}{0.35\textwidth}
	\includegraphics[width=0.35\textwidth]{figure_ml/learning_rate.png}
\end{wrapfigure} 

The gradient update (in SGD) is repeated for each “batch” of events.\\

A full pass of the whole dataset (i.e. all batches) is called an epoch.\\

A typical training foresee iteration on multiple epochs.\\

The size of the update step can be controlled with a multiplicative factor called “learning rate”. Learning rate can be adapted over time.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\linewidth]{figure_ml/real_lr.png}
\end{figure}
\FloatBarrier

\clearpage
\subsection{Training and overfitting}

\begin{wrapfigure}{r}{0.35\textwidth}
	\includegraphics[width=0.35\textwidth]{figure_ml/training_overfitting.png}
\end{wrapfigure} 
As discussed previously if the capacity is large enough the network could “overfit” on the training dataset.

\begin{itemize}
	\item Have a separate, stat independent, validation/generalization sample
	\item Evaluate performance (with “loss” or with other metrics) on the validation sample
	\item Training results depends on many choices
	\begin{itemize}
		\item Size of batches (amount of “noise”)
		\item Learning rate (how much you move along the gradient at
		each iteration)
		\item Gradient Descent algorithm
		\item Capacity of the network
	\end{itemize}
\end{itemize}

\subsection{Neural Networks, computers and mathematics}
ANN use a fairly limited and simple set of operations
\begin{itemize}
	\item Many operation are simply represented with linear algebra
	\item Non linear function are typically applied, repeated, to multiple inputs (hence can be “vectorized”)
	\item Gradient Descent works by knowing the derivatives of the functions involved in the NN calculations (weights, activations) and in the loss
\end{itemize}

Datasets are represented as multidimensional tensors

\begin{itemize}
	\item The number of indices and the length per index is usually called “shape” and is a tuple with dimension of each index
	\item The first index is the one running the “number of sample in the dataset”, and is sometimes omitted when describing a neural network
\end{itemize}

Classification with multiple category is often converted in the “categorical” representation
\begin{itemize}
	\item I.e. rather than labelling with a scalar “y” (with 0=horse, 1=dog, 2=cat, 3=bird, …) a vector y is used with as many components as the category (with [1,0,0,0]=horse, [0,1,0,0]=dog, etc..)
\end{itemize}
Tools exist to describe mathematically the network structure that are optimized for fast computations on CPU/GPU/TPU
\subsection{Back-propagation}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/backpropagation.png}
\end{figure}
\FloatBarrier


\section{Deep Networks}

\subsection{Deep Feed Forward networks}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/activation_functions.png}
\end{figure}
\FloatBarrier


\subsection{Why going deeper?}
Hold on… wasn’t there a theorem saying that MLP is good enough ? Yes but…
\begin{itemize}
	\item Amount of nodes to represent complex functions can be too high
	\item Learning the weights on finite samples could be too difficult
\end{itemize}

Advantages of Deep architectures

\begin{itemize}
	\item Hierarchical structure can allow easier “abstraction” by the network with early layers computing low level features and deeper layers representing more abstract properties 
	\item Number of neurons and connections needed to represent the same function highly reduced in many realistic cases
\end{itemize}
I primi layer imparano features più semplici, quelli dopo imparano features sempre di più alto livello.

\subsection{Activation functions}
\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/activation_functions.png}
\end{figure}
\FloatBarrier

\newpage
\subsection{Deep architectures}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.85\linewidth]{figure_ml/mcc_NN}
\end{figure}
\FloatBarrier

\newpage

\subsection{Dropout and regularization methods}

NN training is a numerical process. Often the number of samples is limited hence the gradient accuracy is not great. Several regularization methods exists to avoid being dominated by stochastic effects.
\begin{itemize}
	\item Caps to the weights (so that individual nodes cannot be worth more than some amount)
	\item \textbf{Dropout} techniques: during the training a fraction of nodes
	is discarded, randomly, at each iteration
	\begin{itemize}
		\item NN more robust to noise
		\item Effectively “augmenting” the input dataset
	\end{itemize}
\end{itemize}


\begin{figure}[ht]
	\centering
	\includegraphics[width=0.5\linewidth]{figure_ml/dropout.png}
\end{figure}


\subsection{(Batch) normalization}
Input features have typically different ranges, means, variance.\\
It is generally useful to “normalize” the input distribution:
\begin{itemize}
	\item Mean zero
	\item Variance 1
\end{itemize}

Often it could be practical to compute the normalization on individual batches rather than full sample (Batch vs full sample ? may depend on your use case).

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\linewidth]{figure_ml/batch_norm.png}
\end{figure}
\FloatBarrier

\section{DNN Tools}


\subsection{Keras}

Keras is a python library that allow to build, train and evaluate NN with many modern technologies.\\
Keras supports multiple backends for actual calculations.\\
Two different syntax are usable to build the network architecture
\begin{itemize}
	\item Sequential: simple linear “stack” of layers
	\item Model (functional API): create more complex topologies
\end{itemize}

Multiple type of “Layers” are supported

\begin{itemize}
	\item Dense: the classic fully connected layer of a FF network
	\item Convolutional layers
	\item Recurrent layers
\end{itemize}

Multiple type of activation functions.\\
Various optimizers and gradient descent techniques.

\subsection{Other common tools}

Common alternative to keras

\begin{itemize}
	\item Pytorch (trending up!) 
	\item Sonnet 
	\item Direct usage of TensorFlow (or other backends, e.g. Theano)
	\begin{itemize}
		\item Need to write yourself some of the basics of NN training
		\item Especially useful to develop new ideas (e.g. a new descent technique, a new type of basic unit/layer)
	\end{itemize}
\end{itemize}

\subsection{Keras Sequential example}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\linewidth]{figure_ml/seq_ex.png}
\end{figure}
\FloatBarrier
\subsection{Keras “Model” Functional API}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/keras_model.png}
\end{figure}
\FloatBarrier

\subsection{A (modernized) MLP in keras}

\begin{minted}{python}
	from keras.models import Model
	from keras.layers import Input, Dense
	x = Input(shape=(32,))
	hid = Dense(32, activation=”relu”)(x)
	out = Dense(1, activation=”sigmoid”)(hid)
	model = Model(inputs=x, outputs=out)
	model.summary()
	from keras.utils import plot_model
	plot_model(model, to_file='model.png')
\end{minted}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/modernized_mlp.png}
\end{figure}
\FloatBarrier

\section{From the 1995 to 2010}

\begin{minted}{python}
	from keras.models import Model
	from keras.layers import Input, Dense
	x = Input(shape=(32,))
	hid = Dense(32, activation=”sigmoid”)(x)
	out = Dense(1, activation=”sigmoid”)(hid)
	model = Model(inputs=x, outputs=out)
\end{minted}

\begin{center}
	$\downarrow$
\end{center}

\begin{minted}{python}
	from keras.models import Model
	from keras.layers import Input, Dense
	x = Input(shape=(32,))
	b = Dense(32,activation=”relu”)(a)
	c = Dense(32,activation=”relu”)(b)
	d = Dense(32,activation=”relu”)(c)
	e = Dense(32,,activation=”sigmoid”)(d)
	model = Model(inputs=x, outputs=e)
\end{minted}

\section{Training a model with Keras}

\begin{minted}{python}
	from keras.layers import Input, Dense
	from keras.models import Model
	# This returns a tensor
	inputs = Input(shape=(784,))
	# a layer instance is callable on a tensor, and returns a tensor
	x = Dense(64, activation='relu')(inputs)
	x = Dense(64, activation='relu')(x)
	predictions = Dense(10, activation='softmax')(x)
	# This creates a model that includes
	# the Input layer and three Dense layers
	model = Model(inputs=inputs, outputs=predictions)
	model.compile(optimizer='rmsprop',
	loss='categorical_crossentropy',
	metrics=['accuracy'])
	model.fit(data, labels) # starts training
\end{minted}



\section{Keras Layers}
\subsection{Keras basic layers}

\begin{itemize}
	\item Basic layers
	\begin{itemize}
		\item Inputs
		\item Dense
		\item Activation
		\item Dropout
	\end{itemize}
	\item Convolutional layers (for next week)
	\begin{itemize}
		\item Conv1D/2D/3D
		\item ConvTranspose or “Deconvolution”
		\item UpSampling and ZeroPadding
		\item MaxPooling, AveragePooling
		\item Flatten
	\end{itemize}
	\item More stuff
	\begin{itemize}
		\item Recursive layers
		\item ...check the keras docs...
	\end{itemize}
\end{itemize}

\subsection{Callbacks}
During training some “callbacks” can be passed to the fit function.
\begin{itemize}
	\item E.g. to monitor the progress of the training
	\item To adapt the training
	\begin{itemize}
		\item Stop if no improvements in the last N epochs
		\item Change learning rate (reduce) if no improvements in the last M epochs
	\end{itemize}
	\item Some callbacks are predefined in keras, other can be user implemented
\end{itemize}

\begin{minted}{python}
	from keras.callbacks import EarlyStopping, ReduceLROnPlateau
	# train
	history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,
	validation_data=(X_test, y_test),
	callbacks = [
	EarlyStopping(monitor='val_loss', patience=10, verbose=1),
	ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1)
	])
\end{minted}

\section{\textit{Assignment 1}}

\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=0.4\textwidth]{figure_ml/ass1.png}
\end{wrapfigure} 
\quad
\begin{itemize}
	\item Partition a 2D region with a simple function that returns true vs false having x1,x2 as arguments
	\begin{itemize}
		\item E.g. x1>x2 or x1*2>x2 or x1 > 1/x2 or … whatever...
	\end{itemize}
	\item Generate 1000 samples
	\item Create a classifier with a MLP or a DNN with similar number of parameters that approximate the function above
\end{itemize}
Link: \\
\href{https://colab.research.google.com/drive/1OOZIT1AFV7IaHajrruOJ6AmZeZkGeBJa?usp=sharing}{Exercise1}\\
\href{https://colab.research.google.com/drive/1ghow_mdPfIOPkALZAS2ubUxIUFRwhotS?usp=sharing}{Solution}

\section{\textit{Assignment 2}}
\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=0.4\textwidth]{figure_ml/ass2.png}
\end{wrapfigure} 
\quad
\begin{itemize}
	\item Let’s try to implement a \textbf{regression} with DNN in keras
	\item Invent a function of x1,x2,x3,x4,x5
	\item Generate some data
	\item Create a Feed Forward model (with 1 or more hidden layers)
	\item What should we change compared to the classification problem?
	\begin{itemize}
		\item What is the loss function to use?
		\item Which activation function in last layer?
	\end{itemize}
	\item Try to make a histogram of the residuals on the validation sample
	\begin{itemize}
		\item residuals=(y\_predicted - y\_truth)
	\end{itemize}
\end{itemize}

Link: \\
\href{https://colab.research.google.com/drive/131B2QwLAm1Ct7e5KdYgRPLIBHGUY05j5?usp=sharing}{Exercise2}\\
\href{https://colab.research.google.com/drive/1_J3EO4IpDoYk1BKIQcxxazxmKqCmLfGJ?usp=sharing}{Solution}

\newpage
\section{\textit{Giovedì 10 novembre - Lezione 14}}

\section{Convolutional and recurrent networks}

\subsection{Classification of images}

Come si fa a processare un'immagine con una rete neurale?\\

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.25\linewidth]{figure_ml/classif.png}
\end{figure}
\FloatBarrier

Images are data structure with 2 or 3 indices: X,Y or X,Y,channel (=R,G,B)
\begin{itemize}
	\item Shape of the input dataset (Nsamples, Width, Height, nchannels)
	\item nchannels is typically 1 (B\&W), 3 (RGB) or 4 with transparency
\end{itemize}
We can use FF networks to classify images
\begin{itemize}
	\item Reshape the input tensor with the “Flatten” keras layer
	\begin{figure}[ht]
		\centering
		\begin{subfigure}{.3\textwidth}
			\centering
			\includegraphics[width=0.9\linewidth]{figure_ml/classif1.png}
		\end{subfigure}%
		\begin{subfigure}{.3\textwidth}
			\centering
			\includegraphics[width=0.9\linewidth]{figure_ml/classif2.png}
		\end{subfigure}%
		\begin{subfigure}{.3\textwidth}
			\centering
			\includegraphics[width=0.9\linewidth]{figure_ml/classif3.png}
		\end{subfigure}
	\end{figure}
	
	
	\item Use multiple dense layers with a final one for one-hot encoding output
\end{itemize}
Limitations of this approach:
\begin{itemize}
	\item If the image is translated, even by a single pixel in x or y, the network may not recognize as “similar” to the untranslated image
	\item Nearby pixels in “Y” (or even the same pixel but in a different color) are not treated any differently than far away pixels
\end{itemize}
We know that our problem has some invariance. We know that input data has some locality information.

\subsection{Exploit invariance and locality}

\begin{wrapfigure}{r}{0.3\textwidth}
	\includegraphics[width=0.3\textwidth]{figure_ml/windows.png}
\end{wrapfigure} 
\quad
\begin{itemize}
	\item Suppose you want to count windows in a 800x600	picture with houses
	\begin{itemize}
		\item With an MLP or DFF you have 800x600x3(RGB)=1.4M inputs
		\item Each node process independently some part of the image
		\item The initial “Dense” connection should converge to something with lot of “zero” weights because far away pixel points have no reason to be considered at the same time in order to detect	local features
		\item => the problem cannot be managed this way
	\end{itemize}
\end{itemize}

But the problem is translation invariant!

\begin{itemize}
	\item “Windows” are local features, you can just analyze a patch of the image \textbf{(locality)}
	\item A window is a window no matter if it is top left or bottom right of	your image (\textbf{Invariance)}
	\item And actually windows are made of even more local features (some borders/frame, some uniform area, a squared shape)
\end{itemize}

\subsection{Can we exploit problem invariance?}

Convolutional neural networks (CNN) attempt to exploit invariance against spatial translations.
\begin{itemize}
	\item Smaller networks (locality !)
	\item Acting on a single patch of the image
	\item Stacking multiple such Convolutional Layers one after the other
	\item Use “subsampling” layer to scale from local to global
\end{itemize}

Hierarchical approach

\begin{itemize}
	\item Early layers learn local features
	\item Subsampling reduce the information extracted from a given “patch”
	\item A final flatten+one or more dense layers is used to reach the final target
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\linewidth]{figure_ml/cnn.png}
\end{figure}
\FloatBarrier

Il vantaggio di questo approccio è che ognuna delle reti che alleniamo vedrà un numero di input molto maggiore, dato che da ogni immagine prendiamo più subsample.


\subsection{Limitations}

The linear algebra formalism we use can handle nicely images, hence implement nicely CNN (translation invariance along x and y).\\

There are more invariances out there! (Rotation, Scale, Luminosity).\\

So currently the networks have to learn them all.\\
We can do tricks to increase the number of samples in our datasets with augmentation techniques (i.e. apply random transformations of scale, rotation etc..).\\
“Built-in” invariance (such as the x-y one) has the advantage of reducing by orders of magnitude the number of weights to learn.

\subsection{Understanding the dimensions of the convolution}

\begin{itemize}
	\item Convolution can be 1D, 2D, 3D
	\item Kernel size, typically square (MxM) with M odd (but can be any shape)
	\item Padding: how to we handle borders? We can do only “valid” windows (no padding) or process borders as if there were zeros (or other values) outside
	\item Each “point” in the 1D, 2D, 3D matrix can have multiple features (e.g. R,G,B)
	\item Each Convolutional layer have mutiple outputs (filters) for every “patch” it scans on (one optimized to detect if the patch is uniformly filled, one looking for vertical lines, etc..)
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\linewidth]{figure_ml/convolution.png}
\end{figure}
\FloatBarrier

Stride: di quanto sposto il kernel ad ogni iterazione? Posso spostarmi di 1 (ho overlap), oppure mi sposto della kernel size, o della metà etc.




\subsection{Pooling (subsampling)}

\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=0.4\textwidth]{figure_ml/pooling.png}
\end{wrapfigure}

Pooling layers are simply finding maxima or computing average in patches of some convolution layer output.\\
Pooling is used to reduce the space dimensionality after a convolutional layer.
\begin{itemize}
	\item The Conv “filters” look for features (e.g. a filter may look for cats eyes)
	\item The Pooling layer checks if in a given 	region some filtered fired (there was a cat eye somewhere in this broader region)
\end{itemize}

\subsection{Typical CNN architecture}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/cnn_arch.png}
\end{figure}
\FloatBarrier

\subsection{More on convolution}


Convolution is a way to correlate \textbf{local} input information and to reduce the NN size by sharing the weights of the nodes across all repeated patches.\\

What if I have multiple objects, with no local correlation, but with multiple features (like R,G,B channels) and I want to process them all in the same way?
\begin{itemize}
	\item 1x1 convolution!
	\item Conv1D is usually enough (as the x-y coordinates have no meanin here)
	\item The symmetry here is that all “objects” are the same
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.3\linewidth]{figure_ml/more_conv.png}
\end{figure}
\FloatBarrier

\textbf{Example :} Particles in a detector with information about 4-vector, tracking hits, calorimeter deposits, p-ID etc… and want to preprocess them one by one before using them for some higher level task


\subsection{Bounding Box}

\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=0.35\textwidth]{figure_ml/stop_bb.png}
\end{wrapfigure}

In order to predict “where” an object is a “bounding box” is defined.
\begin{itemize}
	\item Coordinates of two opposite corners
	\item Essentially a “regression” problem
\end{itemize}

Not simple to extend to multiple objects in a single image, YOLO (You Only Look Once) algorithm is an option \url{https://pjreddie.com/darknet/yolo/}\\
\begin{itemize}
	\item Divide the image in cells, in each cell you predict up to N bounding box corners (relative to the cell position) 
	\item Pick only cells with high score (and cluster multiple predictions of the same bb)
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\linewidth]{figure_ml/bb.png}
\end{figure}
\FloatBarrier


\subsection{Transfer learning}

\begin{wrapfigure}{r}{0.5\textwidth}
	\includegraphics[width=0.48\textwidth]{figure_ml/tl.png}
\end{wrapfigure}

If learn to process images of a given size, can we apply that to different size.
\begin{itemize}
	\item If the “scale” is the same, the convolutional part can work unchanged
	\item The dense (when present) anyhow need to be adapted/retrained
\end{itemize}

Transfer learning is a technique to reuse a network training for a task to2 perform another task with reduced retraining.
\begin{itemize}
	\item E.g. a Conv2D network meant for image
	processing have initial layers processing “local
	features”... that is not very domain specific (if
	you trained on flowers images it may work on
	animals too)
	\item Very useful when the available sample of the proper domain is small
	\begin{itemize}
		\item E.g. annotated medical images are
		harder to get than labelled real world
		pictures
	\end{itemize}
\end{itemize}


\subsection{Variable length, sequences and causality}

What if the input size has a variable length? For example:
\begin{itemize}
	\item Text translations
	\item Identification of “jets” of particle in High Energy Physics
\end{itemize}
In many case sequences have still a concept of locality and translation invariance
\begin{itemize}
	\item “A cat” or “the cat” are two sentences, both containing “cat” but in different position
\end{itemize}
Sequences often also have implied ordering
\begin{itemize}
	\item “The cat eat a mouse” and “The mouse eat a cat” have different meanings
\end{itemize}


\subsection{Exploiting time invariance}

Some problems are “time invariant” (recognize words in a sentence (written or spoken))\\
Order matters and some causality is implied in the sequence. Length of the inputs or the output may not be fixed.\\

\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=0.35\textwidth]{figure_ml/t_invariance.png}
\end{wrapfigure}

Recurrent Networks (RNN)
\begin{itemize}
	\item Iterative networks with output passed again as input
	\begin{itemize}
		\item Allow some “memory” of the previous inputs and/or some internal “state” of what the network understood so far in the sequence
	\end{itemize}
	\item Most commonly used RNN are LSTM (Long Short Term Memory) and GRU (Gated Recurrent Unit)
\end{itemize}

\subsection{LSTM and GRU}
\begin{itemize}
	\item LSTM and GRU are RNN units with additional features to control their “memory”
	\item “Gates” allow to control (keep or drop) input, output and internal state
	\item The advantage of gated units is that they can forget so
	that when processing a sequence they focus on the
	relevant part (e.g. when processing a text we may know that each time we encounter a space the word is over)
\end{itemize}

Ultimamente questi concetti sono stati estesi ai cosiddetti \textit{meccanismi di attenzione}.


\begin{figure}[ht]
	\centering
	\begin{subfigure}{.33\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/lstm.png}
	\end{subfigure}%
	\begin{subfigure}{.33\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/gru.png}
	\end{subfigure}%
	\begin{subfigure}{.33\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{figure_ml/gates.png}
	\end{subfigure}
\end{figure}

\subsection{Different ways of processing time series}

Recurrent Networks can be used to implement networks with variable number of inputs and outputs (Encoding, Decoding, Sequence2Sequence)

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/t_series.png}
\end{figure}
\FloatBarrier


\subsection{Keras basic layers}


\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=0.35\textwidth]{figure_ml/keras_layers.png}
\end{wrapfigure}
\quad
\begin{itemize}
	\item Convolutional layers
	\begin{itemize}
		\item Flatten
		\item Conv1D/2D/3D
		\item ConvTranspose or “Deconvolution”
		\item UpSampling and ZeroPadding
		\item MaxPooling, AveragePooling
		\item Flatten
	\end{itemize}
\end{itemize}

\begin{itemize}
	\item Recurrent layers
	\begin{itemize}
		\item LSTM
		\item GRU
		\item SimpleRNN
		\item TimeDistributed
		\item ConvLSTM2D
	\end{itemize}
\end{itemize}



\subsection{More on LSTM}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/more_lstm.png}
\end{figure}
\FloatBarrier

\subsection{Using LSTM}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/using_lstm.png}
\end{figure}
\FloatBarrier


\section{\textit{Assignment 3}}

Create a CNN that recognize squares and circles in an image. Let’s try three variations:

\begin{enumerate}
	\item Classify: does it contain a rectangle or a circle?
	\item Count circles and rectangles when there is more than one in the dataset
	\item Find the position (bounding box) of the circle or rectangle
\end{enumerate}

\url{https://colab.research.google.com/drive/1kRP1NfbL3hj9xIHAnfMEx9ug76ozGeqR}\\

\href{https://colab.research.google.com/drive/1KHjAsly12wQnrENOgJhF1XKnRFAGmAA6#scrollTo=YiUPPdZ6pNsi}{Solution}


\section{\textit{Assignment 4}}


Try building from scratch a LSTM that find the maximum length and its position in a sequence of two dimensional vectors.\\

\begin{itemize}
	\item Generate some data
	\item Build a network with one LSTM layer followed by a Dense one
\end{itemize}


\href{https://colab.research.google.com/drive/1AyK6r9VG7rV0ZDjqDXu1q0ROEfAAwlU7?usp=sharing}{Solution}


\newpage

\section{\textit{Lunedì 14 novembre - lezione 15}}
\section{Autoencoders and Generative Networks}

\subsection{Dimensionality reduction task}

Avevamo visto l'algoritmo PCA che permette di fare riduzione della dimensionalità tramite un algoritmo unsupervised.\\

We have as input N numbers, we want to transform them to M numbers, with M < N, that contains as much information as possible of the initial numbers.\\

PCA is a possible way to do this dimensionality reduction
\begin{itemize}
	\item Do PCA, and only save the coordinate along the 1st (or first X) axis
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/dim_reduction.png}
\end{figure}
\FloatBarrier

There are (even simple) data distributions where PCA is not going to help.\\
\textbf{Autoencoders} can help with this task
\begin{itemize}
	\item Encode, decode, define a loss based on input vs output difference
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.65\linewidth]{figure_ml/autoencoder.png}
\end{figure}
\FloatBarrier

Gli autoencoder sono delle reti che hanno due parti: codifica e decodifica. La codifica cerca di ridurre i nostri dati da uno spazio multidimensionale a uno spazio più piccolo.\\ La fase di decoding, partendo dalla rappresentazione complessa deve tornare all'input approssimato.\\
Calcolando una loss function tra l'input approssimato e l'input "vero" ci permette di fare un unsupervised learning.


\section{Autoencoder example}



\begin{figure}[ht]
	\centering
	\includegraphics[width=0.65\linewidth]{figure_ml/bottleneck.png}
\end{figure}
\FloatBarrier


\begin{itemize}
	\item Create a “bottleneck” to reduce the
	information
	\begin{itemize}
		\item A layer with fewer nodes than the input
		and output
	\end{itemize}
	\item Define a loss by comparing Output to Input
	\begin{itemize}
		\item This is an unsupervised algorithm!
		\item No need to have labels
	\end{itemize}
	\item The content of the bottleneck layer is the	“compressed representation” or “code”
\end{itemize}

How can we do it in Keras?\\
\texttt{model.fit(X,X)} <= the target is the input

\subsection{Generative models}
\begin{wrapfigure}{r}{0.5\textwidth}
	\includegraphics[width=0.45\textwidth]{figure_ml/generative_models.png}
\end{wrapfigure} 
\quad
\begin{itemize}
	\item We may want to generate new samples from a distribution we learned
	\begin{itemize}
		\item Generating fake images of animals, actors, dresses, etc..
		\item E.g. for creating simulations of LHC events
	\end{itemize}
	\item In many case we want to “conditionally” generate new samples
	\begin{itemize}
		\item Generate a full picture of a product from a hand made sketch
		\item Create color image from B\&W 
		\item Generate realistic “reconstructed LHC event” from generated quarks and leptons
	\end{itemize}
	\item Two powerful methods
	\begin{itemize}
		\item With Autoencoders:
		\begin{itemize}
			\item Train an autoencoder on the data you want to mimic
			\item Take the trained “decoder” and start decoding a vector of random noise
			\item This works best with so called “Variational Autoencoders”
			\begin{itemize}
				\item Latent space representing “mean and variance” of the learned	features (tutorial \href{https://towardsdatascience.com/variational-autoencoders-as-generative-models-with-keras-e0c79415a7eb}{link})
			\end{itemize}
		\end{itemize}
		\item With Generative Adversarial Networks
	\end{itemize}
\end{itemize}

\subsection{Generative Adversarial Networks}

\begin{wrapfigure}{r}{0.5\textwidth}
	\includegraphics[width=0.45\textwidth]{figure_ml/gan.png}
\end{wrapfigure}

GAN works with two independent networks:

\begin{itemize}
	\item A generator
	\item A discriminator
\end{itemize}

The two networks “compete” against each other

\begin{itemize}
	\item The \textbf{discriminator} tries to distinguish samples of the original training dataset from samples generated by the \textbf{generator}
	\item The generator tries to create samples starting from random noise
	\item For the \textbf{discriminator} training we use a mixture of real and generated samples
	\begin{itemize}
		\item No labels are needed in the original	sample as we can label “0” vs “1” the
		samples coming from generator vs original
	\end{itemize}
	\item \textbf{Generator} loss is controlled by the \textbf{discriminator} being able to recognize the fake
\end{itemize}
in pratica abbiamo ottenuto un algoritmo \textit{supervised}. Il concatenamento Generatore + Discriminatore dovrebbe restituire sempre "\textit{fake}".

\subsection{GAN progress}


\begin{figure}[ht]
	\centering
	\includegraphics[width=0.33\linewidth]{figure_ml/dogs.png}
	\caption{2014: “dogs with three heads”}
\end{figure}
\FloatBarrier

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.33\linewidth]{figure_ml/faces.png}
	\caption{2018: coherent generation of faces. See also \url{https://thispersondoesnotexist.com/}}
\end{figure}


\begin{figure}[ht]
	\centering
	\includegraphics[width=0.33\linewidth]{figure_ml/pacman.png}
	\caption{2019: re-create a		playable video game	just by looking at videos of an existing one (so far PacMan). \quad	2021: GANTheftAuto}
\end{figure}


In realtà le GAN stanno passando di moda... Un altra cosa interessante sono i \textit{Normalising Flow} di cui però non parleremo.

\newpage

\section{\textit{Assignment 5}}

\begin{wrapfigure}{r}{0.5\textwidth}
	\includegraphics[width=0.4\textwidth]{figure_ml/ass5_1.png}
	\includegraphics[width=0.4\textwidth]{figure_ml/ass5_2.png}
\end{wrapfigure} 


Create an autoencoder to compress a ring like distribution
\begin{itemize}
	\item As the input is 2 dimensional, can only be 1 number
\end{itemize}
Steps for the exercise
\begin{itemize}
	\item Generate 1000 events in a ring with 0.95<R<1.05
	\item Create an autoencoder with
	\begin{itemize}
		\item An input with dimension 2
		\item 2 encoding hidden layers with $\sim$50 nodes per layer
		\item A latent layer with a single node (sigmoid output) <= give it a name to later reuse
		\item 2 decoding hidden layers with $\sim$50 nodes per layer
		\item An output with 2 nodes
	\end{itemize}
	\item Reuse the latent layer to create two models
	\begin{itemize}
		\item Encoder (i.e. Input -> latent)
		\item Decoder (i.e. latent -> output)
	\end{itemize}
	\item Make few tests like:
	\begin{itemize}
		\item How are (0,1) and (1,0) mapped to “the code”
		\item If we scan the code from 0 to 1, how does it map to (x,y)
	\end{itemize}
\end{itemize}

\href{https://colab.research.google.com/drive/128MRt1zD5iRLhqcUrZz6Bjjndebm7ZSU?usp=sharing}{Esercizio}\\
\href{https://colab.research.google.com/drive/1-mP435EXwv77Z4sEWbMlnVwvtPeWuseD?usp=sharing}{Soluzione}

\section{\textit{Assignment 6}}

\begin{wrapfigure}{r}{0.5\textwidth}
	\includegraphics[width=0.4\textwidth]{figure_ml/ass6.png}
\end{wrapfigure} 

Follow the tutorial at the following \href{https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/}{link}.\\

Nicely following a similar approach to what we had in this lectures: start from something simple and under your complete control instead of loading the usual ML datasets (MNIST, Iris, etc..)

\begin{itemize}
	\item Generate points in a x1,x2 plane following a known function
	\item Ask the GAN to produce “samples” that look like our dataset (i.e. follow the same distribution)
\end{itemize}

\href{https://colab.research.google.com/drive/17Ad1AjATCVbkMaSInfTmryZYK52qLRox#scrollTo=Y7Yhi844aP2Y&uniqifier=1}{solution}.\\


\textbf{nota:} ci vogliono tante epoche per far convergere un oggetto del genere!


$\star$\textbf{Nota:} Per generare immagini si usano encoding e deconding convolutivi, così come nella GAN. Si usano layer convolutional e de-convonutional (Conv2DTranspose).

$\star$Un problema delle GAN è che non c'è un modo quantitativo di capire come stanno performando. Non c'è una metrica ovvia per capire se le cose stanno andando bene.\\


le GAN non sono un granché nell'ambito scientifico, perché non possiamo controllare le proprietà statistiche dei dati che generiamo.\\

Un nuovo pardigma generativo è chiamato \textbf{Normalising Flow}\\


\textbf{Almeno un paio domande per ogni modulo}

\newpage

\section{\textit{Giovedì 17 novembre - Lezione 16}}
\section{Graph Neural Networks}

\subsection{Why graph networks?}

\begin{wrapfigure}{r}{0.5\textwidth}
	\includegraphics[width=0.5\textwidth]{figure_ml/graph_nets.png}
\end{wrapfigure} 

Classical ML algorithms works on multi-index
tensors (euclidean/cartesian space). Data in many case is not easily fitting tensor structure. Approximations introduced to re-cast data in that shape
\begin{itemize}
	\item binning (information loss)
	\item removal of relations
	\item creation of sparse (lot of zeros) data structures
\end{itemize}

We know how to exploit invariance and
locality in text and images, how about other
data topologies?\\
Alcuni dati hanno necessariamente delle relazioni tra loro, e non è ovvio come scrivere queste relazioni in uno struttura tensoriale.

\subsection{Example of datasets}

Plenty of datasets can be represented with graphs.\\
Especially important when there are links between objects

\begin{figure}[ht]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figure_ml/datasets_ex1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figure_ml/datasets_ex2}
	\end{subfigure}%
\end{figure}
\subsection{Graph structures in physics}

\begin{itemize}
	\item Parton shower / Feynman diagrams
	\item Tracking detectors / hits - tracks
	\item fMRI links of activity in different areas
	\item The “galactic web”
\end{itemize}


\begin{figure}[ht]
	\centering
	\begin{subfigure}{.75\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figure_ml/graph_phys}
	\end{subfigure}%
	\begin{subfigure}{.25\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figure_ml/feynman}
	\end{subfigure}%
\end{figure}

\subsection{Sparse datasets}


Graphs are useful also when your data is a list of values
that would result in a sparse format if you try to bin it and
put it on a grid.\\
Example: particles from a jet at LHC:
\begin{itemize}
	\item Charged particle very precisely measured
	\item Different measurements from tracking vs calo detectors
\end{itemize}

Even if no link exists, as long as some “distance” can be
defined a graph structure can be created looking at
nearest neighbors. That allows computation that is “local” in that distance

\begin{figure}[ht]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figure_ml/sparse}
	\end{subfigure}%
	\begin{subfigure}{.6\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figure_ml/neighbors}
	\end{subfigure}%
\end{figure}


\subsection{Locality and invariance}

\begin{wrapfigure}{r}{0.4\textwidth}
	\includegraphics[width=0.4\textwidth]{figure_ml/conv_img}
\end{wrapfigure} 

AI learns better when the problems
invariance are taken into account in the
architecture.
\begin{itemize}
	\item Less parameters to learn, less examples needed
	\item CNNs have x,y translation invariance
	\item LSTM/GRU have time shift invariance
	\item GNN => invariance of the calculation on each
	node
\end{itemize}

Hierarchical extraction of features from local
to global also reduce the number of parameters.
\begin{itemize}
	\item CNN focus on a patch
	\item GNN focus on a node and its connected neighbors
\end{itemize}


\begin{tcolorbox}[width=\textwidth,colback={white},title={Some language dictionary },colbacktitle=cyan,coltitle=black]
	\begin{itemize}
		\item \textbf{Vertices} $\rightarrow$ the nodes of the graph
		\item \textbf{Edges} $\rightarrow$ the connections between the vertices
		\item \textbf{Degree} $\rightarrow$ the number of edges of a given vertex (i.e. the number of vertices connected to it)
		\item \textbf{Directed vs undirected} $\rightarrow$ edges having a specific direction or being bi-directional
		\item \textbf{Bipartite} $\rightarrow$ vertices are divided in two subsets and edges connect only
		vertices from one subset to the other
		\item \textbf{Connected component} $\rightarrow$ a subset of the graph that are linked to each other by a path (i.e. a set of edges)
	\end{itemize}
\end{tcolorbox}


\subsection{Adjacency matrix}

\begin{itemize}
	\item Edges can be represented as an adjacency matrix
	\begin{itemize}
		\item $A_{ij}$ = 1 if connected
		\item $A_{ij}$ = 0 if not connected
	\end{itemize}
	\item Symmetrical for Undirected graphs
	\item $A_{ij} \neq A_{ji}$ for directed graphs
	\item $A_{ij}$ can be weights
	\item Quite often the matrix is full of zeros (i.e. sparse)
	\item Alternative representation in \textbf{COO}(rdinate) format:
	\begin{itemize}
		\item List of triplets (i,j,value) or doublets (i,j) if value only = 1
		\item Much cheaper for sparse matrices
		\item Used by tensorflow\_geometric
	\end{itemize}
\end{itemize}

	\begin{figure}[ht]
	\centering
	\begin{subfigure}{.3\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figure_ml/adj_matrix}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figure_ml/adj2}
	\end{subfigure}%
	\begin{subfigure}{.3\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{figure_ml/adj3}
	\end{subfigure}
\end{figure}
\FloatBarrier

\subsection{Data on a graph}
\begin{itemize}
	\item Vertices
	\item Edges
	\item Global
\end{itemize}

Position of node can be treated as a special attribute.\\

A GNN typically produces additional data for nodes, edges and global (I.e. the output of a GNN layer is still a graph
structure)

\begin{figure}[ht]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.8\linewidth]{figure_ml/datagraph1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.8\linewidth]{figure_ml/datagraph2}
	\end{subfigure}%
\end{figure}
\FloatBarrier
\subsection{Tasks}

\begin{itemize}
	\item Node tasks such as
	classification or regression
	\item Prediction of new links (i.e.
	edges)
	\item Clustering of nodes 
	\item Tasks on the full graph (e.g classification/regression)
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\linewidth]{figure_ml/tasks}
\end{figure}
\FloatBarrier
\subsection{Learn new representation on nodes}

In a CNN each Conv+Pooling layer extracts “new features”, from lower level to higher level.\\

Similarly working on a graph we want to create “new features” on the nodes,
edges, or the full graph with multiple iterations\\

Updates can be done in sequence edge -> node -> global and iterated\\

Two steps are needed:
\begin{itemize}
	\item Create a new representation for each part of the graph 
	\item Have a permutation invariant function to go from edges to vertices, from edges to global and
	from vertices to global
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\linewidth]{figure_ml/repr.png}
\end{figure}
\FloatBarrier
Il pooling è necessario perché il numero di connessioni che ha ogni nodo è variabile. Lo step di poolng non solo riduce l'informazione da tanti a uno, ma deve anche essere invariante per traslazione.

\subsection{Update of edges, nodes, global state}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/ang}
\end{figure}
\FloatBarrier
\subsection{Propagate information}

With multiple iterations the information flows across the graph

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/propagate}
\end{figure}
\FloatBarrier

\subsection{Message passing}
The flow of information can be seen as some “messages” passed across the graph.\\
In many case the graph network architecture is simplified and does not require all
functions to depend on all possible inputs.\\
A simple “message passing” can be achieved in a factorized approach:
\begin{itemize}
	\item A “message” is built on the on edges taking as input the states of the two nodes and the edge features, then,
	on each node, it is accumulated with a permutation invariant function accessing all messages from all edges
	connected to that node
	\item Permutation invariant operations are typically Max, Sum, Mean (=> equivalent to CNN Pooling layers!) [stiamo parlando di operazioni su vettori di feature (ad es massimo elemento per elemento del vettore.)]
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\linewidth]{figure_ml/mess_pass}
\end{figure}
\FloatBarrier


\subsection{How/what do we train?}

Accumulating functions are typically not tainable (Sum, Mean, Max etc…)\\
Update functions \textit{can} be DNNs.

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/hw_train}
\end{figure}
\FloatBarrier

\subsection{Example: b-tag at LHC}
Nice \href{https://indico.cern.ch/event/1086716/contributions/5052326/attachments/2543061/4379499/flavor_tagging_HLLHC_nilotpal.pdf}{talk at Higgs 2022} conference by N. Kakati 

\begin{itemize}
	\item Jets are seen as a set of constituents
	\item No sorting, no casting into images
	\item Locality in eta,phi
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\linewidth]{figure_ml/btag}
\end{figure}
\FloatBarrier


\subsubsection{Example: b-tag at LHC with intermediate targets}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\linewidth]{figure_ml/example_btag}
\end{figure}
\FloatBarrier


\subsubsection{Example: b-tag at LHC with intermediate targets}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\linewidth]{figure_ml/btag_results}
\end{figure}
\FloatBarrier


\section{Tools}

A simple tool for creating GraphNetworks is pytorch “geometric”.
\begin{itemize}
	\item Many simplified architecture already implemented
	\item Handles the “loops” over nodes, edges etc..
	\item Handles data in “graph” representation
\end{itemize}

\texttt{torch\_geometric.data} is the class for handling
graph data

\begin{itemize}
	\item Allow to specify nodes features (x) and a separate tensor for “position features” (pos)
	\item Graph connections are using the COO format, i.e. the list of index i to index j connections (edge\_index)
	\item Edge features (edge\_attr) can also be given
\end{itemize}

Torch geometric handles “batches” of graphs
by creating a “super graph” that has multiple
connected components
\begin{itemize}
	\item i.e. the adjacency matrix is block diagonal
	\item An additional “batch” tensor will be passed around in
	all functions in order to correctly factorize the various components of the graph
\end{itemize}

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{figure_ml/tools.png}
\end{figure}

\subsection{How do we build a network in pytorch?}

Similar to Keras Model API
\begin{itemize}
	\item You need to compose different layers
	\item Activation functions are not in the layer but should be applied on top
	\item A model is typically a class that in the constructor creates the objects that are needed and in the “forward” function plugs them together
\end{itemize}


The key function to implement is hence “forward”.

\begin{minted}{python}
	class Feedforward(torch.nn.Module):
	def __init__(self, input_size, hidden_size):
	super(Feedforward, self).__init__()
	self.input_size = input_size
	self.hidden_size = hidden_size
	self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)
	self.relu = torch.nn.ReLU()
	self.fc2 = torch.nn.Linear(self.hidden_size, 1)
	self.sigmoid = torch.nn.Sigmoid()
	def forward(self, x):
	hidden = self.fc1(x)
	relu = self.relu(hidden)
	output = self.fc2(relu)
	output = self.sigmoid(output)
	return output
\end{minted}

\subsection{How do we train a network in pytorch?}
Each step of the training is handled “by hand”

\begin{minted}{python}
	criterion = torch.nn.BCELoss()
	optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)
	model.train() #set the model in a trainable state
	epoch = 20
	for epoch in range(epoch):
	#reset the gradient (otherwise it is accumulated)
	optimizer.zero_grad()
	
	# Forward pass, i.e. compute the prediction
	y_pred = model(x_train)
	
	# Compute Loss (squeeze() removes the size 1 dimensions)
	loss = criterion(y_pred.squeeze(), y_train)
	print('Epoch {}: train loss: {}'.format(epoch,loss.item()))
	
	# Backward pass
	loss.backward() #compute the gradient
	optimizer.step() #update the weights
\end{minted}

\section{Exercise: our first GNN with pytorch}

We try to classify (again) rectangle vs
circle, but this time assuming we have a point cloud rather than an image.

\begin{itemize}
	\item I.e. we give N measurements of x,y
	coordinates of random sampling points of
	our rectangle vs circle
	\item We can try both generating points only on
	the boundary or filling the full figure
\end{itemize}

A point cloud has no “edges”, but we
can build some using KNN
\begin{itemize}
	\item For each node we found the K (e.g. 10)
	nearest neighbors and connect them
\end{itemize}

We use a particular architecture called
“EdgeConv”
\begin{itemize}
	\item Our edge message is a trainable MLP
	taking as input both the node features (just
	positions in our case) and the difference
	vector between the two nodes
\end{itemize}

\begin{figure}[ht]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.8\linewidth]{figure_ml/ex_pytorch1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.6\linewidth]{figure_ml/ex_pytorch2}
	\end{subfigure}%
\end{figure}
\FloatBarrier

\href{https://colab.research.google.com/drive/1dPSV1ADBf2oxRyUJeEKeR0VC9ngP02lm#scrollTo=3ke3AYJhuSEY}{Solution}


