\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Machine Learning}{203}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\textit  {Gio 3 novembre - Lezione 12}}{203}{section*.392}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Introduction to Machine Learning}{203}{section*.393}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Topics}{203}{section*.394}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Machine Learning Basics}{203}{section*.395}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Types of typical ML problems}{204}{section*.396}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Function approximation}{204}{section*.397}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Model and Hyper-parameters}{204}{section*.399}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Parameters}{205}{section*.400}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Objective function}{205}{section*.401}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Objective function: binary cross entropy}{205}{section*.402}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Learning / Training}{206}{section*.405}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Supervised learning}{206}{section*.406}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Unsupervised learning}{206}{section*.409}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Supervised vs unsupervised}{207}{section*.411}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Reinforcement learning (not covered in this lectures)}{207}{section*.414}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Capacity and representational power}{207}{section*.416}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Generalization}{209}{section*.420}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Regularization}{209}{section*.423}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Hyperparameters(model) optimization}{209}{section*.425}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{K-folding cross validation}{210}{section*.427}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Nella figura i dati sono divisi solo in 2 (test e training), ma si possono dividere in 3 come abbiamo visto prima\relax }}{210}{figure.caption.428}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Inference}{210}{section*.429}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Accuracy, Precision, Sensitivity, Specificity}{210}{section*.430}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Examples of ML techniques}{211}{section*.432}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Linear regression (Supervised)}{211}{section*.433}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Principal Component Analysis (aka PCA) (Unsupervised)}{211}{section*.434}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Nearest neighbors}{212}{section*.437}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces  Figures from \url  {https://scikit-learn.org/stable/modules/neighbors.html}. \relax }}{212}{figure.caption.438}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Decision trees}{212}{section*.439}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Ensembles of trees}{213}{section*.441}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Bagging\relax }}{213}{figure.caption.443}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Gradient Boosting\relax }}{213}{figure.caption.444}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Limitations of decision trees}{213}{section*.445}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Many more ML techniques!}{213}{section*.447}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{What do we need to create our first ML program}{214}{section*.449}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Hands-on}{214}{section*.450}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\textit  {Lun 7 novembre - lezione 13}}{241}{section*.451}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Introduction to Artificial Neural Networks}{241}{section*.452}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Artificial Neural Networks}{242}{section*.453}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{(Artificial) neural networks: the “Model”}{242}{section*.454}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Brief history, highs and lows}{242}{section*.456}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Complexity growth}{243}{section*.458}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Performance on classic problems}{243}{section*.460}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{My favorite performance examples}{243}{section*.462}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{OpenAI GPT3}{244}{section*.463}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Neural Nets Basic elements}{244}{section*.464}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{A neural network node: the artificial neuron}{244}{section*.465}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{The MLP model}{244}{section*.467}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Universal approximation theorem}{245}{section*.469}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Example (1-D input)}{245}{section*.470}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces \url  {https://towardsdatascience.com/can-neural-networks-really-learn-any-function-65e106617fc6}\relax }}{246}{figure.caption.472}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Training of an MLP}{246}{section*.473}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Training a NN}{246}{section*.475}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{How to find a minimum?}{246}{section*.477}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Not as simple as you would imagine}{247}{section*.479}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Learning rate, epochs and batches}{247}{section*.481}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Training and overfitting}{249}{section*.484}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Neural Networks, computers and mathematics}{249}{section*.486}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Back-propagation}{249}{section*.487}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Deep Networks}{250}{section*.489}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Deep Feed Forward networks}{250}{section*.490}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Why going deeper?}{250}{section*.492}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Activation functions}{251}{section*.493}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Deep architectures}{252}{section*.495}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Dropout and regularization methods}{253}{section*.497}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{(Batch) normalization}{253}{section*.499}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{DNN Tools}{254}{section*.501}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Keras}{254}{section*.502}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Other common tools}{254}{section*.503}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Keras Sequential example}{254}{section*.504}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Keras “Model” Functional API}{254}{section*.506}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{A (modernized) MLP in keras}{255}{section*.508}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{From the 1995 to 2010}{255}{section*.510}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Training a model with Keras}{256}{section*.511}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Keras Layers}{256}{section*.512}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Keras basic layers}{256}{section*.513}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Callbacks}{257}{section*.514}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\textit  {Assignment 1}}{257}{section*.515}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\textit  {Assignment 2}}{257}{section*.517}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\textit  {Giovedì 10 novembre - Lezione 14}}{259}{section*.519}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Convolutional and recurrent networks}{259}{section*.520}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Classification of images}{259}{section*.521}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Exploit invariance and locality}{259}{section*.524}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Can we exploit problem invariance?}{260}{section*.526}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Limitations}{260}{section*.528}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Understanding the dimensions of the convolution}{260}{section*.529}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Pooling (subsampling)}{261}{section*.531}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Typical CNN architecture}{261}{section*.533}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{More on convolution}{261}{section*.535}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Bounding Box}{262}{section*.537}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Transfer learning}{262}{section*.540}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Variable length, sequences and causality}{263}{section*.542}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Exploiting time invariance}{263}{section*.543}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{LSTM and GRU}{263}{section*.545}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Different ways of processing time series}{264}{section*.547}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Keras basic layers}{264}{section*.549}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{More on LSTM}{265}{section*.551}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Using LSTM}{265}{section*.553}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\textit  {Assignment 3}}{265}{section*.555}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\textit  {Assignment 4}}{266}{section*.556}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\textit  {Lunedì 14 novembre - lezione 15}}{267}{section*.557}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Autoencoders and Generative Networks}{267}{section*.558}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Dimensionality reduction task}{267}{section*.559}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Autoencoder example}{267}{section*.562}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Generative models}{268}{section*.564}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Generative Adversarial Networks}{269}{section*.566}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{GAN progress}{269}{section*.568}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces 2014: “dogs with three heads”\relax }}{269}{figure.caption.569}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces 2018: coherent generation of faces. See also \url  {https://thispersondoesnotexist.com/}\relax }}{270}{figure.caption.570}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces 2019: re-create a playable video game just by looking at videos of an existing one (so far PacMan). \hskip 1em\relax 2021: GANTheftAuto\relax }}{270}{figure.caption.571}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\textit  {Assignment 5}}{270}{section*.572}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\textit  {Assignment 6}}{271}{section*.574}\protected@file@percent }
\@setckpt{machine_learning}{
\setcounter{page}{272}
\setcounter{equation}{0}
\setcounter{enumi}{3}
\setcounter{enumii}{1}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{0}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{15}
\setcounter{table}{0}
\setcounter{pp@next@reset}{0}
\setcounter{parentequation}{0}
\setcounter{AM@survey}{0}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{Item}{48}
\setcounter{Hfootnote}{11}
\setcounter{bookmark@seq@number}{399}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{tcbbreakpart}{1}
\setcounter{tcblayer}{0}
\setcounter{tcbrastercolumn}{0}
\setcounter{tcbrasterrow}{0}
\setcounter{tcbraster}{0}
\setcounter{lstnumber}{1}
\setcounter{tcblisting}{0}
\setcounter{FancyVerbLine}{8}
\setcounter{linenumber}{1}
\setcounter{LN@truepage}{271}
\setcounter{FV@TrueTabGroupLevel}{0}
\setcounter{FV@TrueTabCounter}{0}
\setcounter{FV@HighlightLinesStart}{0}
\setcounter{FV@HighlightLinesStop}{0}
\setcounter{FancyVerbLineBreakLast}{0}
\setcounter{float@type}{32}
\setcounter{minted@FancyVerbLineTemp}{15}
\setcounter{minted@pygmentizecounter}{211}
\setcounter{listing}{0}
\setcounter{section@level}{1}
\setcounter{lstlisting}{0}
}
