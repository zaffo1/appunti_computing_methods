\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Machine Learning}{203}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\textit  {Gio 3 novembre - Lezione 12}}{203}{section*.392}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Introduction to Machine Learning}{203}{section*.393}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Topics}{203}{section*.394}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Machine Learning Basics}{203}{section*.395}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Types of typical ML problems}{204}{section*.396}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Function approximation}{204}{section*.397}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Model and Hyper-parameters}{204}{section*.399}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Parameters}{205}{section*.400}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Objective function}{205}{section*.401}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Objective function: binary cross entropy}{205}{section*.402}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Learning / Training}{206}{section*.405}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Supervised learning}{206}{section*.406}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Unsupervised learning}{206}{section*.409}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Supervised vs unsupervised}{207}{section*.411}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Reinforcement learning (not covered in this lectures)}{207}{section*.414}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Capacity and representational power}{207}{section*.416}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Generalization}{208}{section*.420}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Regularization}{209}{section*.423}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Hyperparameters(model) optimization}{209}{section*.425}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{K-folding cross validation}{209}{section*.427}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Nella figura i dati sono divisi solo in 2 (test e training), ma si possono dividere in 3 come abbiamo visto prima\relax }}{210}{figure.caption.428}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Inference}{210}{section*.429}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Accuracy, Precision, Sensitivity, Specificity}{210}{section*.430}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Examples of ML techniques}{210}{section*.432}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Linear regression (Supervised)}{210}{section*.433}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Principal Component Analysis (aka PCA) (Unsupervised)}{211}{section*.434}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Nearest neighbors}{211}{section*.437}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces  Figures from \url  {https://scikit-learn.org/stable/modules/neighbors.html}. \relax }}{211}{figure.caption.438}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Decision trees}{212}{section*.439}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Ensembles of trees}{212}{section*.441}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Bagging\relax }}{212}{figure.caption.443}\protected@file@percent }
\@writefile{lof}{\con